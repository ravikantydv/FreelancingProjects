{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc53ca94",
   "metadata": {},
   "source": [
    "Given training documents: 4 documents with\n",
    "\n",
    "D1 (sports): China soccer\n",
    "\n",
    "D2 (sports): Japan baseball\n",
    "\n",
    "D3 (politics): China trade \n",
    "\n",
    "D4 (politics): Japan Japan exports\n",
    "\n",
    "\n",
    "### SOLUTION :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722f487",
   "metadata": {},
   "source": [
    "Calculate the prior probabilities of each class based on the training documents. \n",
    "\n",
    "In this case, we have 2 classes (Sports and Politics) and 4 training documents. Two of the documents are sports-related and two are politics-related, so the prior probabilities are:\n",
    "\n",
    "P(Sports) = 2/4 = 0.5\n",
    "\n",
    "P(Politics) = 2/4 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bc4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0750fa8b",
   "metadata": {},
   "source": [
    "### Procedure--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4b7d7",
   "metadata": {},
   "source": [
    "##### Step 1: Preparing the training data\n",
    "\n",
    "The training data consists of 4 documents, each labeled as either \"Sports\" or \"Politics\". We split the documents into their constituent words, and use these words to build a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0562e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "train_docs = [\n",
    "    (\"China soccer\", \"Sports\"),\n",
    "    (\"Japan baseball\", \"Sports\"),\n",
    "    (\"China trade\", \"Politics\"),\n",
    "    (\"Japan exports\", \"Politics\")\n",
    "]\n",
    "\n",
    "# Vocabulary\n",
    "vocab = set()\n",
    "for doc, label in train_docs:\n",
    "    vocab.update(doc.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa784d",
   "metadata": {},
   "source": [
    "##### Step 2: Calculating the prior probabilities\n",
    "\n",
    "The prior probabilities of each class are simply the proportion of training documents that belong to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a785f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of documents for each class\n",
    "num_docs_sports = sum(1 for _, label in train_docs if label == \"Sports\")\n",
    "num_docs_politics = sum(1 for _, label in train_docs if label == \"Politics\")\n",
    "\n",
    "# Calculating the prior probabilities for each class\n",
    "prior_sports = num_docs_sports / len(train_docs)\n",
    "prior_politics = num_docs_politics / len(train_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a413f4",
   "metadata": {},
   "source": [
    "##### Step 3: Counting the number of words in each class\n",
    "\n",
    "We count the number of occurrences of each word in each class, and use Laplace smoothing to avoid zero probability estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e325d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplace smoothing parameter\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c538007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of words in each class\n",
    "word_counts_sports = {word: 0 for word in vocab}\n",
    "word_counts_politics = {word: 0 for word in vocab}\n",
    "for doc, label in train_docs:\n",
    "    words = doc.split()\n",
    "    for word in words:\n",
    "        if label == \"Sports\":\n",
    "            word_counts_sports[word] += 1\n",
    "        else:\n",
    "            word_counts_politics[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "155bc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Laplace smoothing to the word counts\n",
    "for word in vocab:\n",
    "    word_counts_sports[word] += alpha\n",
    "    word_counts_politics[word] += alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7477fd",
   "metadata": {},
   "source": [
    "##### Step 4: Classifying the test documents\n",
    "\n",
    "For each test document, we calculate the likelihood probabilities of each word given each class, and apply Bayes' rule to calculate the posterior probabilities of each class given the document. We then classify the document as the class with the highest posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab5b3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_docs = [\n",
    "    \"soccer\",\n",
    "    \"Japan\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0a47a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soccer: Sports\n",
      "Japan: Politics\n"
     ]
    }
   ],
   "source": [
    "# Classifying the test documents\n",
    "for test_doc in test_docs:\n",
    "    # Calculating the likelihood probabilities for each class\n",
    "    likelihood_sports = 1\n",
    "    likelihood_politics = 1\n",
    "    words = test_doc.split()\n",
    "    for word in words:\n",
    "        # Probability of the word given the Sports class\n",
    "        prob_word_given_sports = (word_counts_sports.get(word, 0)) / (sum(word_counts_sports.values()))\n",
    "        likelihood_sports *= prob_word_given_sports\n",
    "        # Probability of the word given the Politics class\n",
    "        prob_word_given_politics = (word_counts_politics.get(word, 0)) / (sum(word_counts_politics.values()))\n",
    "        likelihood_politics *= prob_word_given_politics\n",
    "    \n",
    "    # Applying Bayes' rule to calculate the posterior probabilities\n",
    "    posterior_sports = likelihood_sports * prior_sports\n",
    "    posterior_politics = likelihood_politics * prior_politics\n",
    "    \n",
    "    # Classifying the test document\n",
    "    if posterior_sports > posterior_politics:\n",
    "        print(f\"{test_doc}: Sports\")\n",
    "    else:\n",
    "        print(f\"{test_doc}: Politics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63455402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the likelihood probabilities\n",
    "p_soccer_sports = (2 + 1) / (8 + 2)\n",
    "p_soccer_politics = (1 + 1) / (8 + 2)\n",
    "p_japan_sports = (1 + 1) / (8 + 2)\n",
    "p_japan_politics = (2 + 1) / (8 + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63259d",
   "metadata": {},
   "source": [
    "Since P(\"Politics\" | \"Japan\") > P(\"Sports\" | \"Japan\"), we classify the document as \"Politics\".\n",
    "\n",
    "Therefore, the final classifications for the test documents are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a55d0",
   "metadata": {},
   "source": [
    "soccer: Sports\n",
    "\n",
    "Japan: Politics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
