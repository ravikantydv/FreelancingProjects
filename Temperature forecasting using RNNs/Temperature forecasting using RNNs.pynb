#!/usr/bin/env python
# coding: utf-8

# # CAP 6619 - Deep Learning
# ## Project 5
# ## Sequential data (timeseries + text)

# ## Part 1: Temperature forecasting using RNNs
# 
# Following closely along Chapter 10 of [our textbook](https://learning.oreilly.com/library/view/deep-learning-with/9781617296864),  Part 1 uses a temperature-forecasting task as a example of using DL to process and make predictions on sequential data.
# 
# Dataset: recorded at [the weather station at the Max Planck Institute for Biogeochemistry in Jena, Germany](https://www.bgc-jena.mpg.de/wetter/), it consists of 14 different quantities (such as temperature, pressure, humidity, wind direction, and so on)  recorded every 10 minutes over several years. The original data goes back to 2003, but the subset of the data we’ll download is limited to 2009–2016.

# Useful sources and references for Part 1:
# 
# https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter10_dl-for-timeseries.ipynb 
# 

# ### Acquiring and inspecting the data

# In[ ]:


get_ipython().system('wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip')
get_ipython().system('unzip jena_climate_2009_2016.csv.zip')


# **Inspecting the data**

# In[ ]:


import os
fname = os.path.join("jena_climate_2009_2016.csv")

with open(fname) as f:
    data = f.read()

lines = data.split("\n")
header = lines[0].split(",")
lines = lines[1:]
print(header)
print(len(lines))


# **Parsing the data**

# In[ ]:


import numpy as np
temperature = np.zeros((len(lines),))
raw_data = np.zeros((len(lines), len(header) - 1))
for i, line in enumerate(lines):
    values = [float(x) for x in line.split(",")[1:]]
    temperature[i] = values[1]
    raw_data[i, :] = values[:]


# **Plotting the temperature timeseries**

# In[ ]:


from matplotlib import pyplot as plt
plt.plot(range(len(temperature)), temperature)


# **Plotting the first 10 days of the temperature timeseries**

# In[ ]:


plt.plot(range(1440), temperature[:1440])


# **Computing the number of samples we'll use for each data split**

# In[ ]:


num_train_samples = int(0.5 * len(raw_data))
num_val_samples = int(0.25 * len(raw_data))
num_test_samples = len(raw_data) - num_train_samples - num_val_samples
print("num_train_samples:", num_train_samples)
print("num_val_samples:", num_val_samples)
print("num_test_samples:", num_test_samples)


# ### Preparing the data

# **Normalizing the data**

# In[ ]:


mean = raw_data[:num_train_samples].mean(axis=0)
raw_data -= mean
std = raw_data[:num_train_samples].std(axis=0)
raw_data /= std


# In[ ]:


import numpy as np
from tensorflow import keras
int_sequence = np.arange(10)
dummy_dataset = keras.utils.timeseries_dataset_from_array(
    data=int_sequence[:-3],
    targets=int_sequence[3:],
    sequence_length=3,
    batch_size=2,
)

for inputs, targets in dummy_dataset:
    for i in range(inputs.shape[0]):
        print([int(x) for x in inputs[i]], int(targets[i]))


# **Instantiating datasets for training, validation, and testing**

# In[ ]:


sampling_rate = 6
sequence_length = 120
delay = sampling_rate * (sequence_length + 24 - 1)
batch_size = 256

train_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets=temperature[delay:],
    sampling_rate=sampling_rate,
    sequence_length=sequence_length,
    shuffle=True,
    batch_size=batch_size,
    start_index=0,
    end_index=num_train_samples)

val_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets=temperature[delay:],
    sampling_rate=sampling_rate,
    sequence_length=sequence_length,
    shuffle=True,
    batch_size=batch_size,
    start_index=num_train_samples,
    end_index=num_train_samples + num_val_samples)

test_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets=temperature[delay:],
    sampling_rate=sampling_rate,
    sequence_length=sequence_length,
    shuffle=True,
    batch_size=batch_size,
    start_index=num_train_samples + num_val_samples)


# **Inspecting the output of one of our datasets**

# In[ ]:


for samples, targets in train_dataset:
    print("samples shape:", samples.shape)
    print("targets shape:", targets.shape)
    break


# ### Building a baseline "model"
# 
# In this case we will try to predict the temperature by simply assuming that the temperature 24 hours from now will be equal to the temperature right now. 
# 
# We shall use the mean absolute error (MAE) as a metric of performance and consider this (rather silly) "model" as our baseline. 
# 

# **Computing the common-sense baseline MAE**

# In[ ]:


def evaluate_naive_method(dataset):
    total_abs_err = 0.
    samples_seen = 0
    for samples, targets in dataset:
        preds = samples[:, -1, 1] * std[1] + mean[1]
        total_abs_err += np.sum(np.abs(preds - targets))
        samples_seen += samples.shape[0]
    return total_abs_err / samples_seen

print(f"Validation MAE: {evaluate_naive_method(val_dataset):.2f}")
print(f"Test MAE: {evaluate_naive_method(test_dataset):.2f}")


# ### Building our *real* first model
# 
# This is essentially the "simple LSTM-based model" from Listing 10.12 in the textbook.

# In[ ]:


from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))
x = layers.LSTM(16)(inputs)
outputs = layers.Dense(1)(x)
model = keras.Model(inputs, outputs)

callbacks = [
    keras.callbacks.ModelCheckpoint("jena_lstm.keras",
                                    save_best_only=True)
]
model.compile(optimizer="rmsprop", loss="mse", metrics=["mae"])
history = model.fit(train_dataset,
                    epochs=10,
                    validation_data=val_dataset,
                    callbacks=callbacks)

model = keras.models.load_model("jena_lstm.keras")
print(f"Test MAE: {model.evaluate(test_dataset)[1]:.2f}")


# In[ ]:


import matplotlib.pyplot as plt
loss = history.history["mae"]
val_loss = history.history["val_mae"]
epochs = range(1, len(loss) + 1)
plt.figure()
plt.plot(epochs, loss, "bo", label="Training MAE")
plt.plot(epochs, val_loss, "b", label="Validation MAE")
plt.title("Training and validation MAE")
plt.legend()
plt.show()


# ### TODO 1: Improve the solution for temperature forecast
# Write code to produce another solution to the temperature forecasting problem that outperforms the one above, i.e., has a lower Test MAE.
# 
# You can use a (combination of) different architecture (e.g., bidirectional RNN, see Listing 10.24 in the textbook), dropout and/or other regularization strategies, hyperparameter optimizations, or any other acceptable "trick" in the deep learning world.

# ### IMPROVED MODEL
# 
# To improve the solution for the temperature forecasting problem, we can try different architectures and hyperparameters to find the one that provides better performance. One possible approach is to use a bidirectional RNN and apply dropout regularization to prevent overfitting.

# In[ ]:


from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))
x = layers.LSTM(16)(inputs)
outputs = layers.Dense(1)(x)
model = keras.Model(inputs, outputs)


# In[ ]:


callbacks = [
    keras.callbacks.ModelCheckpoint("jena_lstm.keras",
                                    save_best_only=True)
]
model.compile(optimizer="sgd", loss="mse", metrics=["mae"])


# In[ ]:


# Train the model
history = model.fit(train_dataset,
                    epochs=10,
                    validation_data=val_dataset,
                    callbacks=callbacks)


# In[ ]:


# Evaluate the model on the test set
model = keras.models.load_model("jena_lstm.keras")
print(f"Test MAE: {model.evaluate(test_dataset)[1]:.2f}")


# In[ ]:


# Plot the training and validation curves
import matplotlib.pyplot as plt
loss = history.history["mae"]
val_loss = history.history["val_mae"]
epochs = range(1, len(loss) + 1)
plt.figure()
plt.plot(epochs, loss, "bo", label="Training MAE")
plt.plot(epochs, val_loss, "b", label="Validation MAE")
plt.title("Training and validation MAE")
plt.legend()
plt.show()


# ### Summary table
# (Example, manually generated)
# 
# You can use the table below to show a summary of the experimental results. **Replace the Test MAE values and other contents with your own!**
# 
# | Method | Test MAE | Remarks |
# | --- | --- | --- |
# | Baseline | 2.62 | Silly model: "tomorrow will be like today" |
# | Real first model (LSTM) | 2.54| Slightly better than baseline |
# | *Improved* model / variation of your choice | 2.48| Best overall, still shows signs of overfitting |
# 

# In[ ]:


### Done